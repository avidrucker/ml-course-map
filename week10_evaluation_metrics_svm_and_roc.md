# Week 10: Evaluation Metrics, SVM, & ROC
**Evaluation Metrics (topic)**  
- (assertion) ROC stands for Receiver Operating Characteristic; the ROC curve plots the true positive rate against the false positive rate, showing a model’s performance at all thresholds.  
- (assertion) The AUC (Area Under the ROC Curve) summarizes the ROC curve’s information into a single scalar, measuring how well the model ranks positive examples higher than negatives.  
- (assertion) F1 score is the harmonic mean of precision and recall, useful when class imbalance is present.

**Support Vector Classifier (SVC) (topic)**  
- (assertion) SVMs (Support Vector Machines) are used for classification by finding the optimal separating hyperplane that maximizes the margin between classes.  
- (assertion) With nonlinearly separable data, kernel functions transform inputs into higher-dimensional feature spaces where linear separation might become possible.

**Evaluation Metrics (topic)** (additional from sample exam context)
- (task) Given a confusion matrix, compute precision, recall, and F1 score for each class.  
- (task) Choose an appropriate metric depending on whether missing positive cases or misclassifying negatives as positives is more costly (based on domain requirements).
